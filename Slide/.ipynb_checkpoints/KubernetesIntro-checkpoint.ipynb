{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29db2613",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"jumbotron\">\n",
    "    <center>\n",
    "    <h1>Introduzione a Kubernetes</h1>\n",
    "    <h2> Rosario Cannavò, Mario Benissimo</h2>\n",
    "    <h3>A.A. 2021/2022</h3>\n",
    "    </center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671fce53",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/meme4.jpeg\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00dffe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Perchè Kubernetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d1db9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "L’aumento delle applicazioni basate su microservizi ha portato all’aumento dell’utilizzo dei container, in quanto essi offrono il perfetto ambiente per applicazioni piccole e indipendenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22aa5cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Questo trend ha portato ad applicazioni odierne che fanno uso di centinaia di container che venivano gestiti attraverso script handmade o tools privati molto difficili da utilizzare. Questo scenario ha portato alla necessità di avere un tool semplice da usare per l’orchestrazione di container."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53cf671",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/EY4n3mWWAAABqUP.jpg\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72386a9e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cos'è Kubernetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6fc8f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<center>\n",
    "<img src=\"meme/meme1.jpg\" alt=\"drawing\" style=\"width:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a64984",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kubernetes è un tool che permette l’orchestrazione di container sviluppati con tecnologia docker o simile. \n",
    "In altre parole, permette di gestire in modo efficiente le applicazioni containerizzate composte da\n",
    "centinaia di container in diversi ambienti come macchine fisiche, macchine virtuali, ambienti cloud e ambienti di sviluppo ibridi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933532f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quali feature offre Kubernetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c437570c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **High availability**: l’applicazione non ha tempi di inattività, quindi è sempre accessibile dagli utenti."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9837ecc9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Scalability**: con Kubernetes è possibile scalare velocemente le applicazioni gestite quando si presenta più carico su di esse o quando quest’ultimo diminuisce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c080b5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* **Disaster recovery**: se qualcosa dovesse succedere ai dati, kubernetes permette di recuperare i container allo stato precedente al disaster in modo da limitare i danni."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac7eb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Architettura di Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb08a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Un cluster kubernetes è composto da almeno un **nodo master** connesso ad una serie di **worker node**.\n",
    "Ogni worker node ha al suo interno diverse applicazioni containerizzate, quindi, i worker node sono effettivamente le macchine su cui girano le applicazioni.\n",
    "Il master node esegue invece diversi processi kubernetes necessari alla corretta \n",
    "gestione del cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cff204",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Di cosa si occupa il Master Node?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6718392d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Uno dei processi gestiti dal master node è un **server API** (che è a sua volta un container) e non è altro che l'entry point al cluster kubernetes, ovvero, il processo con cui i diversi client si interfacceranno."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5447ce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un altro processo che gira sul nodo master è un **controller manager** il cui compito è quello di tenere sott’occhio la situazione dei vari nodi che compongono il cluster, ad esempio esso ha il compito di capire se qualcosa deve essere riparato, di capire se un container è morto e deve essere riavviato, ecc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ce311",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un terzo processo in esecuzione sul nodo master è lo **scheduler** il cui compito è quello di schedulare i container sui diversi nodi del cluster in base al carico di lavoro e alle risorse disponibili su ogni nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0b137",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il quarto componente del nodo master è un **etcd**, ovvero un archivio di valori chiave che mantiene in ogni momento lo stato corrente del cluster kubernetes, mantiene dunque tutti i dati di configurazione e tutti i dati di stato di ogni nodo e di ogni container all’interno dello specifico nodo, contiene inoltre lo snapshot del backup e del ripristino utili in fase di disaster recovery. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c5283e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L’ultimo componente di kubernetes che permette ai worker node di comunicare con il master node è una **rete virtuale** che abbraccia tutti i nodi che fanno parte del cluster: tramite questa rete, tutti i nodi del cluster riescono a lavorare effettivamente come un’unica macchina che ha come potenza la somma di tutte le risorse dei vari nodi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbfde3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confusi?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc34ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/img1.jpeg\" alt=\"drawing\" style=\"width:1000px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d54005",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Componenti principali di Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b89e29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/3c00b3383bff1ceb837a177d83c4d526.jpg\" alt=\"drawing\" style=\"width:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a65e1d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Nodi e Pod\n",
    "La component unit  più piccola di kubernetes prende il nome di Pod. Un pod è sostanzialmente un’astrazione posta su di un container, ovvero, un pod non fa altro che creare un ambiente virtuale che viene eseguito su di un container, questo viene fatto perchè kubernetes astrae dalla tecnologia utilizzata dai container che vengono eseguiti, in modo da poterli rimpiazzare senza avere problemi di configurazione.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b431acc",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "E’ importante rimarcare il concetto per cui è buona norma eseguire solo un’applicazione per pod, è possibile eseguire anche più application container all’interno di un pod ma solo in alcuni casi in cui il secondo container contiene qualche servizio laterale necessario al principale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736936ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Per comunicare tra di loro questi pod fanno uso della rete virtuale fornita da kubernetes, questo vuol dire che ogni pod (non il container) avrà un proprio indirizzo ip che permetterà ai pod di comunicare tra di loro.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d290281f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un altro importante concetto di kubernetes è che i pod sono effimeri, ovvero possono morire molto facilmente a causa di problemi di varia natura. Quando questo accade, viene ricreato un nuovo pod che andrà a sostituire quello precedente e che avrà un indirizzo ip diverso, il che è molto scomodo per la comunicazione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131bb81",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Service & Ingress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0600f8a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un service non è altro che un indirizzo ip statico o un indirizzo ip permanente che può essere collegato ad ogni pod. Il lifecycle del pod e del service non sono connessi, questo vuol dire che il pod che andrà eventualmente a sostituire un precedente pod morto avrà lo stesso service, ovvero lo stesso indirizzo ip. Un’altra funzione del service è quella di fare da load balancer del carico che grava sull'applicazione.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c2357c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ad esempio nel caso di un database, collegando un service, avremo la sicurezza che questo servizio sia sempre raggiungibile allo stesso indirizzo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea2bbd9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un altro componente di kubernetes prende il nome di ingress, esso permette di assegnare un nome al service, in questo modo, le richieste dall’esterno passeranno prima verso l’ingress (legato al nodo) che si occuperà poi di effettuare l’inoltro in locale ai vari pod. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea44adf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esempio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6727962",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Immaginiamo uno scenario in cui una webapp comunica con un database MongoDB all'interno di un cluster kubernetes, lo scenario sarebbe il seguente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741b7895",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/sei.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be276d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ConfigMap & Secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f90741b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una configmap è un file di configurazione che contiene dati di configurazione. Grazie alle configmap non è necessario dover creare una nuova immagine per ogni piccolo cambiamento del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7840b90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Parte della configurazione possono essere anche delle password (anch’esse possono cambiare nel ciclo di vita dell’applicazione). Memorizzare una password  come testo in chiaro in un file di configurazione sarebbe poco sicuro, per questo motivo kubernetes introduce un altro componente che prende il nome di secret e viene utilizzato per memorizzare credenziali codificandole in base64, ovviamente questo non basta per la sicurezza quindi il secret file va crittografato utilizzato tool di terze parti.\n",
    "Come per la configmap. il secret va connesso al pod in modo che esso possa visualizzarlo e configurarsi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824e5ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Ritornando al nostro esempio, la sitauazione sarebbe la seguente:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3171f9fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/ces.jpeg\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c24e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9972f39d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un altro concetto molto importante è quello del data storage. \n",
    "Nella pratica quello che si fa è “attaccare” il pod ad uno storage fisico che può essere sia in locale, ovvero nella stessa macchina che ospita il nodo del cluster kubernetes su cui sta girando il pod che in remoto, anche all’esterno del cluster kubernetes. In questo modo, se il pod ospitante il database del nostro esempio dovesse perdersi, i dati rimarrebbero comunque memorizzati in modo persistente su questo storage esterno. \n",
    "Da questa caratteristica è possibile intuire che kubernetes non gestisce lo storage persistente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585255a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f89611",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Si osserva che anzichè effettuare n repliche di un pod, kubernetes offre la possibilità di definire una blueprint e di specificare quante copie vogliamo avere nel nostro pod.\n",
    "Questi blueprint prendono il nome di deployment e sono un’altro componente di kubernetes.\n",
    "Abbiamo detto che un pod è un livello di astrazione costruito su di un container che gira in un nodo del nostro cluster kubernetes.\n",
    "Alla luce di quanto detto è possibile definire un deployment come l’astrazione di un pod."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18877d04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A questo punto, se una delle repliche del pod su cui gira la nostra applicazione dovesse morire, il service inoltrerebbe la richiesta ad un altro pod replica, in questo modo il servizio rimarrebbe accessibile per l’utente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5a784b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/poohmeme.jpeg\" alt=\"drawing\" style=\"width:500px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a16fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c410be8e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Un Job crea uno o più pod e continuerà a riprovare l'esecuzione di essi finché un numero specificato di pod non termina con successo. Man mano che i pod si completano con successo, il job tiene traccia dei completamenti riusciti. Quando viene raggiunto un numero specificato di completamenti riusciti, l'attività (cioè il job) è completa. L'eliminazione di un job fa il clear i pod creati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adc708",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## StatefulSet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a99006",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ponendoci nel caso in cui un database nel nostro cluster dovesse morire, andremmo incontro ad un’altra tipologia di problema in quanto il database ha uno stato (i dati che ospita) e non può essere replicato utilizzando i deployment.\n",
    "Se avessimo diverse repliche del nostro database, tutte dovrebbero avere accesso alla stessa area di memoria condivisa, avremmo bisogno di un meccanismo in grado di gestire quale replica del pod sta scrivendo nello storage e quali repliche stanno invece leggendo in modo da evitare problemi di inconsistenza (race condition).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b6dca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Per evitare questa tipologia di problemi, viene introdotto un ulteriore componente di kubernetes, ovvero gli statefulset. Questi componenti sono stati studiati accuratamente per le applicazioni come i database. \n",
    "A tal proposito, tutte le applicazioni:\n",
    "* **stateful**, come i database, vengono create utilizzando gli statefulset;\n",
    "* **stateless**, come le applicazioni statiche, vengono create utilizzando i deployment;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e0575c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Uno statefulset si occupa quindi sia di gestire la scalabilità del sistema sia della sincronizzazione della lettura e scrittura sul database in modo che i dati al suo interno rimangano consistenti. Nonostante ciò, impostare uno stateful è molto complesso, per tale motivo è molto comune implementare i database al di fuori del cluster k8 e lasciare al suo interno solo le applicazioni stateless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26af32c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/meme2.png\" alt=\"drawing\" style=\"width:380px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a6ebb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Configurazione Kubernetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f347b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tutte le configurazioni del cluster kubernetes passano attraverso il processo api server ospitato dal master node. Al processo api server può essere connessa una UI kubernetes o una CLI come kubernetesCLI per passare i file di configurazione.\n",
    "Tutti i file di configurazione vanno passata all’api server in formato YAML o JSON.\n",
    "\n",
    "La configurazione di kubernetes viene fatta in modo dichiarativo, quindi va dichiarato quello che è l’output desiderato da kubernetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ac192",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## File di configurazione\n",
    "Ogni file di configurazione kubernetes è diviso in 3  in parti:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ac8de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* La prima parte è quella in cui i metadati dei componenti che stiamo creando risiedono;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf50ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* La seconda parte comprende le specification, in questa parte si dichiarano tutte le configurazioni che vogliamo applicare a quel component. All’interno di questa parte gli attributi specificati devono essere inerenti alla tipologia di configurazione che stiamo creando (Deployment o Service, ecc) [ogni componente deve avere il suo file di configurazione];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b6377",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* La terza parte è lo status ma viene generata automaticamente da kubernetes, esso permette di effettuare un confronto tra le feature desiderate e quelle specificate, se qualcosa non combacia kubernetes se ne rende conto e cerca di provvedere, questa specifica sta alla base del meccanismo di self-healing di kubernetes. Tutte le configurazioni sullo status di kubernetes vengono dalla etcd che mantiene in ogni momento le informazioni di stato di ogni elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702603fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Minikube e KubeCTL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efe771",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generalmente in un custer kubernetes in produzione sono presenti almeno due master e almeno due nodi worker.\n",
    "Ogni nodo lavora su una macchina fisica o virtuale separata, quindi, se volessimo effettuare dei test in locale, settare un cluster di questa tipologia sarebbe molto difficile e oneroso dal punto di vista delle risorse, per tale motivo è stato creato minikube. Minikube non è altro che un cluster formato da un solo nodo in cui sia i processi master che i processi worker vengono eseguiti. Questo nodo avrà un container docker preinstallato in modo da avere la possibilità di installare dei container o dei pod su questo nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75951c8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/3.3.png\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110a881",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/1_yZAMZDl7eFQ8xQDaPEbPBg.png\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec03efa4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/1_ylaasu1x_ABHSHXQzhiGaw.png\" alt=\"drawing\" style=\"width:700px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb690dee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Una volta creato questo unico nodo con minikube in locale, è necessario disporre di uno strumento che permetta di interagire con questo cluster, per creare le configurazioni necessarie. Per fare ciò viene utilizzato kubectl, ovvero uno strumento a linea di comando per interagire con il cluster kubernetes. Kubectl non viene utilizzato solo per minikube ma anche per i cluster kubernetes reali."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff65d6b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/kubectl-architecture.png\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc35c86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/pic1.svg\" alt=\"drawing\" style=\"width:800px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80338cd7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2edd19",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/dockerHub.png\" alt=\"drawing\" style=\"width:700px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ae2485",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/pipeline.png\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c858705",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actors\n",
      "BeansTalk\n",
      "NameSpace\n",
      "startKube.sh\n",
      "Authenticating with existing credentials...\n",
      "Login Succeeded\n",
      "* Deleting \"minikube\" in docker ...\n",
      "* Removing /home/rosario/.minikube/machines/minikube ...\n",
      "* Removed all traces of the \"minikube\" cluster.\n",
      "* Successfully deleted all profiles\n",
      "* minikube v1.25.2 on Debian bookworm/sid\n",
      "* Automatically selected the docker driver\n",
      "* Starting control plane node minikube in cluster minikube\n",
      "* Pulling base image ...\n",
      "* Creating docker container (CPUs=2, Memory=3700MB) ...\n",
      "* Preparing Kubernetes v1.23.3 on Docker 20.10.12 ...\n",
      "  - kubelet.housekeeping-interval=5m\n",
      "  - Generating certificates and keys ...\n",
      "  - Booting up control plane ...\n",
      "  - Configuring RBAC rules ...\n",
      "* Verifying Kubernetes components...\n",
      "  - Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "* Enabled addons: default-storageclass, storage-provisioner\n",
      "* Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\n",
      "Entro dentro la cartella NameSpace e creo il namespace su minikube\n",
      "namespace/demospace created\n",
      "Entro dentro la cartella BeansTalk e creo la coda su minikube\n",
      "deployment.apps/beanstalk-dep created\n",
      "service/beanstalk-svc created\n",
      "Entro dentro la cartella Actor e creo i due file di configurazione\n",
      "configmap/beanstalk-configmap created\n",
      "Eseguo il producer\n",
      "job.batch/queue-prod-job created\n",
      "Eseguo il consumer\n",
      "job.batch/queue-consumer-job created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/rosario/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "cd ./Kubernetes\n",
    "ls\n",
    "bash startKube.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c88d0d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                 READY   STATUS              RESTARTS   AGE\n",
      "pod/beanstalk-dep-6674d469f4-t4l2l   1/1     Running             0          11s\n",
      "pod/queue-consumer-job-gpw5m         0/1     ContainerCreating   0          0s\n",
      "pod/queue-consumer-job-snppb         0/1     ContainerCreating   0          0s\n",
      "pod/queue-consumer-job-z9fwf         0/1     ContainerCreating   0          0s\n",
      "pod/queue-prod-job-8rgg9             0/1     ContainerCreating   0          0s\n",
      "\n",
      "NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)     AGE\n",
      "service/beanstalk-svc   ClusterIP   10.106.198.52   <none>        11300/TCP   20s\n",
      "\n",
      "NAME                            READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/beanstalk-dep   1/1     1            1           20s\n",
      "\n",
      "NAME                                       DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/beanstalk-dep-6674d469f4   1         1         1       11s\n",
      "\n",
      "NAME                           COMPLETIONS   DURATION   AGE\n",
      "job.batch/queue-consumer-job   0/1 of 3      0s         0s\n",
      "job.batch/queue-prod-job       0/1           0s         0s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl get all -n demospace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92d85d0",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): pods \"queue-consumer-job-4fk55\" not found\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'kubectl logs queue-consumer-job-4fk55 -n demospace\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_48240/2316954508.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kubectl logs queue-consumer-job-4fk55 -n demospace\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'kubectl logs queue-consumer-job-4fk55 -n demospace\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl logs queue-consumer-job-4fk55 -n demospace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0af082",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"meme/how-you-deploy-a-container-on-kubernetes.jpg\" alt=\"drawing\" style=\"width:900px;\"/>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
